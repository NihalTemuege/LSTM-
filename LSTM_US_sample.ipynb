{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PACKAGES\n",
    "The first step is loading the packages that we will use:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df237f18a47c7ffd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd #data manipulation\n",
    "import numpy as np #data manipulation\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing #preprocessing\n",
    "import math as math\n",
    "\n",
    "import keras as keras #keras package for neural networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense #dense layers\n",
    "from keras.layers import LSTM #LSTM layers\n",
    "from keras.layers import Dropout #Dropout\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pydot as pyd\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import plot_model #plot network's structure\n",
    "import matplotlib.pyplot as plt #plots\n",
    "import time\n",
    "from collections import Counter\n",
    "import os\n",
    "os.chdir('..')\n",
    "import csv #save output\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2a27d82c56f824"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b45d1b242d5b2a12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IMPORT DATA\n",
    "Import data and plot the variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "505ba456ff6a2b4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_US_gm_12= pd.read_csv(r'C:/Users/rneb3bv/Desktop/Inflation_Trade_Thesis/US_Monthly(gm)_csv2.csv',  sep = ',', index_col = 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13e66c4821da7b4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_US_gm_12.plot(kind='line',\n",
    "                subplots=True,\n",
    "                grid=True,\n",
    "                figsize=(12, 12),\n",
    "                title=['Core CPI(yy)', 'Oil(eur_yy)', 'Output Gap', 'NEER(yy)', 'World CPI (yy)', 'US Michigan 5y'],\n",
    "                layout=(3, 2),\n",
    "                sharex=True,\n",
    "                sharey=False,\n",
    "                legend=False,\n",
    "                style=['darkred', 'steelblue', 'dodgerblue', 'slateblue', 'darkslateblue', 'mediumblue',\n",
    "                       'midnightblue'])\n",
    "\n",
    "[ax.set_xlabel('') for ax in plt.gcf().axes]\n",
    "plt.suptitle('Data for the United States', fontsize=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "222b5318a52e1a76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network for the US\n",
    "The first step is to split data into training and test sets. I will be using data from the beginning until 2009 for training and from 2009 to 2015 for testing. I will leave the last 12 observations for out-of-sample testing later. The testing inputs are data from 2014-2015. \n",
    "PS:To construct inflation surprise rate I started from the period of 04/2022-03/2023 and then forecasted previous 12 months and so forth until 01/1982. Here, we have prediction codes for period of 2014-2015.\n",
    "The following function splits a multivariate sequence into samples:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc3485565e5357fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()    \n",
    "    for i in range(len(sequences)):\n",
    "        #find end of pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "        \n",
    "        #check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        #gather input and output\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix - 1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f8a685046090c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "data_US_gm_12.loc['15/04/2004':'15/03/2014', ['CPI']]  #in-sample data\n",
    "data_US_gm_12.loc['15/04/2014':'15/03/2015', ['CPI']]  #out-of-sample target"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbad4367b9ca025"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#inputs\n",
    "in_core_cpi_12 = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['CPI']])\n",
    "in_outgap_12 = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['Output_gap']])\n",
    "in_NEERate_12  = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['NEER']])\n",
    "in_world_cpi_12 = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['World_cpi']])\n",
    "in_oil_e_12   = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['Crude oil']])\n",
    "in_UMic5y_12   = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['US_Michigan_5y']])\n",
    "\n",
    "valin_core_cpi_12 = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['CPI']])\n",
    "valin_outgap_12 = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['Output_gap']])\n",
    "valin_NEERate_12  = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['NEER']])\n",
    "valin_world_cpi_12 = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['World_cpi']])\n",
    "valin_oil_e_12  = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['Crude oil']])\n",
    "valin_UMic5y_12   = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['US_Michigan_5y']])\n",
    "\n",
    "#output\n",
    "out_infl_12 = array(data_US_gm_12.loc['15/01/1982':'15/01/2009', ['CPI']])\n",
    "\n",
    "valout_infl_12 = array(data_US_gm_12.loc['15/01/2009':'15/03/2015', ['CPI']])\n",
    "\n",
    "#reshape to [rows, columns]\n",
    "in_core_cpi_12 = in_core_cpi_12.reshape((len(in_core_cpi_12), 1))\n",
    "in_outgap_12 = in_outgap_12.reshape((len(in_outgap_12), 1))\n",
    "in_NEERate_12  = in_NEERate_12.reshape((len(in_NEERate_12), 1))\n",
    "in_world_cpi_12 = in_world_cpi_12.reshape((len(in_world_cpi_12), 1))\n",
    "in_oil_e_12   = in_oil_e_12.reshape((len(in_oil_e_12), 1))\n",
    "in_UMic5y_12 = in_UMic5y_12.reshape((len(in_UMic5y_12), 1))\n",
    "\n",
    "valin_core_cpi_12 = valin_core_cpi_12.reshape((len(valin_core_cpi_12), 1))\n",
    "valin_outgap_12 = valin_outgap_12.reshape((len(valin_outgap_12), 1))\n",
    "valin_NEERate_12  = valin_NEERate_12.reshape((len(valin_NEERate_12), 1))\n",
    "valin_world_cpi_12 = valin_world_cpi_12.reshape((len(valin_world_cpi_12), 1))\n",
    "valin_oil_e_12   = valin_oil_e_12.reshape((len(valin_oil_e_12), 1))\n",
    "valin_UMic5y_12= valin_UMic5y_12.reshape((len(valin_UMic5y_12), 1))\n",
    "\n",
    "\n",
    "out_infl_12 = out_infl_12.reshape((len(out_infl_12), 1))\n",
    "valout_infl_12 = valout_infl_12.reshape((len(valout_infl_12), 1))\n",
    "\n",
    "#stack columns horizontally\n",
    "dataset_12 = hstack((in_core_cpi_12, in_outgap_12, in_NEERate_12, in_world_cpi_12, in_oil_e_12, in_UMic5y_12, out_infl_12))\n",
    "valset_12= hstack((valin_core_cpi_12, valin_outgap_12, valin_NEERate_12, valin_world_cpi_12, valin_oil_e_12, valin_UMic5y_12, valout_infl_12))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#timesteps\n",
    "n_steps_in, n_steps_out = 12,12 #use 6 observations to predict next 6\n",
    "\n",
    "X_12, y_12 = split_sequences(dataset_12, n_steps_in, n_steps_out)\n",
    "print(X_12.shape, y_12.shape) #shape of input and output = (21, 12, 6) (21, 12)\n",
    "valX_12, valy_12 = split_sequences(valset_12, n_steps_in, n_steps_out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5b8e3898561bfa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Note that I have prepared the data, we can continue with the construction of the model. Lets start by doing an LSTM for multi-step predictions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eddca92c9e55deee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_core_cpi_12 = array(data_US_gm_12.loc['15/04/2014':'15/03/2015', ['CPI']])\n",
    "x_outgap_12 = array(data_US_gm_12.loc['15/04/2014':'15/03/2015', ['Output_gap']])\n",
    "x_NEERate_12  = array(data_US_gm_12.loc['15/04/2014':'15/03/2015', ['NEER']])\n",
    "x_world_cpi_12 = array(data_US_gm_12.loc['15/04/2014':'15/03/2015', ['World_cpi']])\n",
    "x_oil_e_12  = array(data_US_gm_12.loc['15/04/2014':'15/03/2015', ['Crude oil']])\n",
    "x_UMic5y_12 = array(data_US_gm_12.loc['15/04/2014':'15/03/2015', ['US_Michigan_5y']])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bffc29d173396fc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the range of hyperparameters to search\n",
    "param_range = {\n",
    "    'n_units': [50, 100],\n",
    "    'dropout': [0.2, 0.4],\n",
    "    'recurrent_dropout': [0.2, 0.4],\n",
    "    'learning_rate': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "n_features = X_12.shape[2]\n",
    "\n",
    "for n_units in param_range['n_units']:\n",
    "    for dropout in param_range['dropout']:\n",
    "        for recurrent_dropout in param_range['recurrent_dropout']:\n",
    "            for learning_rate in param_range['learning_rate']:\n",
    "                # Build the model\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(n_units,\n",
    "                               activation='tanh',\n",
    "                               return_sequences=True,\n",
    "                               input_shape=(n_steps_in, n_features)))\n",
    "                model.add(LSTM(n_units,\n",
    "                               dropout=dropout,\n",
    "                               recurrent_dropout=recurrent_dropout,\n",
    "                               activation='tanh'))\n",
    "                model.add(Dense(50, activation='tanh'))\n",
    "                model.add(Dense(25, activation='tanh'))\n",
    "                model.add(Dense(n_steps_out))\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                              loss='mse')\n",
    "\n",
    "                # Define early stopping\n",
    "                es = EarlyStopping(monitor='val_loss',\n",
    "                                   mode='min',\n",
    "                                   min_delta=0.01,\n",
    "                                   patience=30,\n",
    "                                   verbose=0)\n",
    "\n",
    "                # Fit the model\n",
    "                fit = model.fit(X_12,\n",
    "                                y_12,\n",
    "                                validation_data=(valX_12, valy_12,\n",
    "                                epochs=500,\n",
    "                                verbose=0,\n",
    "                                callbacks=[es])\n",
    "\n",
    "                # Evaluate the model\n",
    "                val_loss = np.min(fit.history['val_loss'])\n",
    "\n",
    "                # Check if this model has the best loss so far\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model = model\n",
    "\n",
    "#prediction\n",
    "x_input_12 = array([x_core_cpi_12,\n",
    "                 x_outgap_12,\n",
    "                 x_NEERate_12,\n",
    "                 x_world_cpi_12,\n",
    "                 x_oil_e_12,\n",
    "                 x_UMic5y_12])\n",
    "x_input_12 = x_input_12.reshape((1, n_steps_in, n_features))\n",
    "\n",
    "yhat_12 = best_model.predict(x_input_12, verbose=0)\n",
    "print(yhat_12)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcdc2d89e1976d99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning curve "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b096c470e5ce38a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(fit.history['loss'], label='training', color='SteelBlue')\n",
    "plt.plot(fit.history['val_loss'], label='validation', color='DarkRed')\n",
    "plt.legend()\n",
    "plt.show\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f69b0a1503ccfd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_12 = pd.DataFrame(yhat_12.T, index=pd.date_range('15/03/2020',periods=12,freq='M'))\n",
    "predicted_12.columns = ['predicted']\n",
    "\n",
    "predicted_12.plot(color = 'SteelBlue')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "observed_12 = data_US_gm_12.loc['15/04/2020':'15/03/2021', ['CPI']]\n",
    "observed_12.columns = ['observed']\n",
    "\n",
    "observed_12.plot(color = 'DarkRed')\n",
    "plt.show()\n",
    "\n",
    "model_error_12 = array(predicted_12) - array(observed_12)\n",
    "model_error_12 = pd.DataFrame(model_error_12, index=pd.date_range('15/03/2020',periods=12,freq='M'))\n",
    "model_error_12.columns = ['forecast error']\n",
    "\n",
    "model_error_12.plot(color = 'goldenrod')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6a6658b395c3e5ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_error_12.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3e0ab74fbd7768db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Although the LSTM is able to approximate the 'shape' of future inflation, there is still room for improvement. forecast error is around 0.425431 (I haven't set a seed yet, so it may change), implying that the model overestimates inflation (remember that instead of y-yhat , I'm using yht-y, allowing for a more direct interpretation)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "446cbe3630ccaf73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now, we build a prediction iterval for the network. I train the network 50 times with a for loop and store the results in the results variable\n",
    "PS: Ranges for the hyperparameters are selected according to the pattern of each , figured by running the model again and again"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba7ca884c1d5a190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 50\n",
    "results = []\n",
    "for i in range(0, n):\n",
    "# Define the range of hyperparameters to search\n",
    "    param_range = {\n",
    "        'n_units': [50, 100],\n",
    "        'dropout': [0.2, 0.4],\n",
    "        'recurrent_dropout': [0.2, 0.4],\n",
    "        'learning_rate': [0.0001, 0.001]\n",
    "    }\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    n_features = X_12.shape[2]\n",
    "\n",
    "    for n_units in param_range['n_units']:\n",
    "        for dropout in param_range['dropout']:\n",
    "            for recurrent_dropout in param_range['recurrent_dropout']:\n",
    "                for learning_rate in param_range['learning_rate']:\n",
    "                    # Build the model\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(n_units,\n",
    "                                   activation='tanh',\n",
    "                                   return_sequences=True,\n",
    "                                   input_shape=(n_steps_in, n_features)))\n",
    "                    model.add(LSTM(n_units,\n",
    "                                   dropout=dropout,\n",
    "                                   recurrent_dropout=recurrent_dropout,\n",
    "                                   activation='tanh'))\n",
    "                    model.add(Dense(50, activation='tanh'))\n",
    "                    model.add(Dense(25, activation='tanh'))\n",
    "                    model.add(Dense(n_steps_out))\n",
    "\n",
    "                    # Compile the model\n",
    "                    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                  loss='mse')\n",
    "\n",
    "                    # Define early stopping\n",
    "                    es = EarlyStopping(monitor='val_loss',\n",
    "                                       mode='min',\n",
    "                                       min_delta=0.01,\n",
    "                                       patience=30,\n",
    "                                       verbose=0)\n",
    "\n",
    "                    # Fit the model\n",
    "                    fit = model.fit(X_12,\n",
    "                                    y_12,\n",
    "                                    validation_data=(valX_12, valy_12),\n",
    "                                    epochs=500,\n",
    "                                    verbose=0,\n",
    "                                    callbacks=[es])\n",
    "\n",
    "                    # Evaluate the model\n",
    "                    val_loss = np.min(fit.history['val_loss'])\n",
    "\n",
    "                    # Check if this model has the best loss so far\n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        best_model = model\n",
    "\n",
    "    #prediction\n",
    "    x_input_12 = array([x_core_cpi_12,\n",
    "                     x_outgap_12,\n",
    "                     x_NEERate_12,\n",
    "                     x_world_cpi_12,\n",
    "                     x_oil_e_12,\n",
    "                     x_UMic5y_12])\n",
    "    x_input_12 = x_input_12.reshape((1, n_steps_in, n_features))\n",
    "\n",
    "    yhat_12 = best_model.predict(x_input_12, verbose=0)\n",
    "    results.append((yhat_12))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7665f1e0dfb89b3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iter_output = pd.DataFrame(np.concatenate(results)) #build data frame with results\n",
    "iter_output.columns = ['m1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11', 'm12']\n",
    "iter_output"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "99d0a897296df233"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I receive 50 forecast values for each time period i.e. m1 , m2 etc. and take the mean of them to get one forecast value.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee55272d32df35c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_forecast = pd.DataFrame([iter_output['m1'].mean(),\n",
    "                              iter_output['m2'].mean(),\n",
    "                              iter_output['m3'].mean(),\n",
    "                              iter_output['m4'].mean(),\n",
    "                              iter_output['m5'].mean(),\n",
    "                              iter_output['m6'].mean(),\n",
    "                              iter_output['m7'].mean(),\n",
    "                              iter_output['m8'].mean(),\n",
    "                              iter_output['m9'].mean(),\n",
    "                              iter_output['m10'].mean(),\n",
    "                              iter_output['m11'].mean(),\n",
    "                              iter_output['m12'].mean()],\n",
    "                             index=pd.date_range('15/04/2019', periods=12, freq='M'))  #mean dataframe\n",
    "mean_forecast.columns = ['predicted']\n",
    "mean_forecast\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "caa30c7bc27eb3a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standard Errors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c10e2ccfdbdc7f17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "se_forecast = pd.DataFrame([iter_output['m1'].std(),\n",
    "                            iter_output['m2'].mean(),\n",
    "                            iter_output['m3'].mean(),\n",
    "                            iter_output['m4'].mean(),\n",
    "                            iter_output['m5'].mean(),\n",
    "                            iter_output['m6'].mean(),\n",
    "                            iter_output['m7'].mean(),\n",
    "                            iter_output['m8'].mean(),\n",
    "                            iter_output['m9'].mean(),\n",
    "                            iter_output['m10'].mean(),\n",
    "                            iter_output['m11'].mean(),\n",
    "                            iter_output['m12'].mean()],\n",
    "                           index=pd.date_range('15/04/2019', periods=12, freq='m'))  #se dataframe\n",
    "se_forecast.columns = ['predicted']\n",
    "se_forecast"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c4c3b64e9203c1f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot confidence intervals , predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a87d2da8c6f5a1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "upper_bound = mean_forecast + 2 * se_forecast\n",
    "lower_bound = mean_forecast - 2 * se_forecast\n",
    "plt.plot(mean_forecast, label='predicted', color='SteelBlue')\n",
    "plt.plot(upper_bound, label='95% confidence interval', color='SkyBlue')\n",
    "plt.plot(lower_bound, color='SkyBlue')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "46b93902206016d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Observed values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c01eac3d235ebe26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observed = pd.DataFrame(pd.read_csv(r'C:/Users/rneb3bv/Desktop/Inflation_Trade_Thesis/US_Monthly(gm)_csv2.csv',\n",
    "                                    sep=',',\n",
    "                                    skiprows= 447,\n",
    "                                    skipfooter=36,\n",
    "                                    usecols=[1]\n",
    "                                    ))\n",
    "\n",
    "#observed = observed.dropna()\n",
    "observed\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4ff3e81ea07b00d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observed.columns = ['observed']\n",
    "observed.index = pd.date_range('15/04/2019',periods=12,freq='M')\n",
    "observed\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bee6ddb8205d7403"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot for actual values vs predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb6d42a4374fb16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observed\n",
    "plt.plot(mean_forecast, label='predicted', color='SteelBlue')\n",
    "plt.plot(upper_bound, label='95% confidence interval', color='lightblue')\n",
    "plt.plot(lower_bound, color='lightblue')\n",
    "plt.plot(observed, label='observed', color='DarkRed')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "model_error = array(mean_forecast) - array(observed)\n",
    "model_error = pd.DataFrame(model_error, index=pd.date_range('15/04/2019', periods=12, freq='M'))\n",
    "model_error.columns = ['forecast error']\n",
    "\n",
    "model_error.plot(color='goldenrod')\n",
    "plt.show()\n",
    "\n",
    "model_error.mean(), mean_forecast.mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b79bb5f005fdfd85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e5579335b5de8943"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1ce5a7a455cf439f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6c88144ffab18de2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "47b051404f13db6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6a76d562de247420"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
